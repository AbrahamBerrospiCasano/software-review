---
title: "Another Year in Reviews at rOpenSci: DRAFT ANALYTICAL PART"
author: "Noam Ross"
date: "1/16/2017"
output: html_document
---

*Here are some initial stabs at a quantitative look at the review process,
which will be part of my next "Year in Reviews" post.  I'll update with nicer
styling and more text later.  For now this is just an exploration to prompt further
questions. Please let me know if there's something else you want.*

```{r setup, include=FALSE}
library(airtabler)
library(tidyverse)
library(gh)
library(stringi)
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
```

```{r get-data}
baseID = "appZIB8hgtvjoV99D"
reviewers <- air_get(baseID, "Reviewers") %>% as_tibble()
reviews <- air_get(baseID, "Reviews") %>% as_tibble()
packages <- gh("/repos/ropensci/onboarding/issues?labels=package&state=all", .limit=200)
revdata <- list(reviewers=reviewers, reviews=reviews, packages=packages)
saveRDS(revdata, "revdata.rds")
revdata <- readRDS("revdata.rds")
list2env(revdata, envir=environment())
pkg_df <- map_df(packages, function(iss) {
  data_frame(
    pkgname = stri_extract_first_regex(iss$body, "(?<=Package:\\s{1,3})[^\\s\\n]+(?=\\s|\\n)"),
    submitter = iss$user$login,
    editor = iss$assignee$login,
    labels = list(map_chr(iss$labels, "name")),
    status = map_chr(labels, ~stri_subset_regex(.x, "(\\d\\/.*|out-of-scope|pulled)")),
    opened = as.POSIXct(iss$created_at),
    closed = as.POSIXct(if_else(is.null(iss$closed_at), NA_character_, iss$closed_at)),
    title = iss$title,
    url = iss$url,
    iss_no = stri_extract_first_regex(url, "\\d+$")
  )
}) %>% tbl_df()
```

We've grown the reviewer pool considerably.  Here's the number of reviewers
by the reviews they've started and completed:

```{r reviewer-pool}
reviewers = reviewers %>% 
  mutate(n_reviews = map_int(Reviews, length)) %>% 
  mutate(last_review = map(Reviews, function(x) {
    rev_reviews_urls = reviews$onboarding_url[reviews$id %in% x]
    if(!length(rev_reviews_urls)) 
      return(as.POSIXct(NA))
    rev_reviews = unlist(map(stri_extract_first_regex(rev_reviews_urls, "/issues/\\d+"), function(url) {
      pkg_df$closed[stri_extract_first_regex(pkg_df$url, "/issues/\\d+") == url]
    }))
    if(any(is.na(rev_reviews))) {
      last_date = Sys.time()
    } else {
      last_date = as.POSIXct(max(rev_reviews), origin=as.POSIXct("1970-01-01 00:00.00 UTC"))
    }
    return(last_date)
  })) %>% 
  mutate(last_review = as.POSIXct(unlist(last_review), origin=as.POSIXct("1970-01-01 00:00.00 UTC"))) %>% 
  mutate(status = if_else(n_reviews == 0, "Never reviewed",
                          if_else(last_review >= as.POSIXct(Sys.Date() - 1), "Currently reviewing", "Has reviewed"))) %>% 
  mutate(last_review = coalesce(last_review, as.POSIXct("2015-01-01")))
ggplot(reviewers, aes(x=n_reviews)) + geom_bar()
```

And here they are by the date of the end of their last review, with the cutoff
of 6 months shown.  The spike at the beginning is those with no reviews, the spike
at today is those currently reviewing a package.  This is conservative as it
includes packages that are in "holding" mode, with no current expectation as to
when authors will respons to reviews.

We currently have `r nrow(reviewers)` reviewers in the database, and `r sum(reviewers$last_review < as.POSIXct(Sys.Date() - lubridate::days(180)))` have
not done a review in at least six months. `r sum(reviewers$status == "Never reviewed")`
of these are new and have not yet started a review.  We're not even including
here package authors that we have not yet tapped for review, as they are not
yet in the reviewer database.

```{r by-time}
ggplot(reviewers, aes(x=last_review, fill=as.factor(n_reviews))) +
  geom_histogram() +
  geom_vline(xintercept = as.numeric(as.POSIXct(Sys.Date() - lubridate::days(180))))
```

Here is the distribution of review times. Mean review time is ~77 days, with a
long tail but also some being much faster.  This isn't bad considering in an
absolutely perfect scenario:

- 1 week with editor
- 1 week finding reviewers
- 3 weeks reviewing
- 2 weeks revising
- 1 week getting second reviews
- = 8 weeks = 56 days

```{r time-to-accept}
pkg_df = pkg_df %>% 
  mutate(review_time = as.numeric(closed - opened, units="days")) 
ggplot(filter(pkg_df, status=="6/approved"), aes(x=review_time)) + 
  geom_histogram(binwidth = 10) +
  geom_vline(xintercept = mean(pkg_df$review_time, na.rm=TRUE))
```

Overall, review times are holding steady:

```{r times}
ggplot(filter(pkg_df, status=="6/approved"), aes(x=opened, y=review_time)) + geom_point() + geom_smooth(method="lm")
```

Here's the number of pacakges submitted per quarter, highlighting authors with
more than one submittal.  Note that after a flurry
of submissions over last spring and summer, partially driven by our power users,
we're back down to lower rates of submission.  

```{r submission-rate}
top_authors <- pkg_df %>% count(submitter) %>% arrange(desc(n)) %>% filter(n  > 1)
submits = pkg_df %>% 
  mutate(Author = if_else(submitter %in% top_authors$submitter, submitter, "other")) %>% 
  mutate(Author = forcats::fct_relevel(Author, c("other", rev(top_authors$submitter))))

ggplot(submits, aes(x=opened, fill = Author)) +
  geom_histogram(binwidth = 90*24*60*60) +
  scale_x_datetime(date_breaks = "90 days", date_labels = "%b %y") +
  scale_y_continuous(breaks = seq(0, 16, by=2), limits = c(0, 13), expand = c(0,0)) +
  scale_fill_brewer(type = "qual") +
  theme(axis.text.x = element_text(angle = 45, margin =margin(t=10)))
```

Overall, this analysis sort of confirms my priors - we've put a good deal of
effort into improving our process and expanding our reviewer pool, but we've
lost some momentum in increasing rates of submission and expanding our author
base.  This suggests we should be finding ways to do more outreach for new
authors.

The reported time it takes to review remains similar.  The median time reported 
to complete a review is `r median(reviews$review_hours, na.rm=TRUE)` hours.

```{r review-hours}
ggplot(reviews, aes(x=review_hours)) + geom_histogram(binwidth = 1)
```

A question - does the time taken to complete reviews change as reviewers gain experience?

```{r}
revs <- reviews %>%
  mutate(rev_name = map_chr(reviewer, function(rr) {
    if(is.null(rr)) {
      return(NA_character_)
    } else {
      return(reviewers$github[reviewers$id == rr])
    }
  })) %>% 
  arrange(rev_name, onboarding_url) %>% 
  group_by(rev_name) %>% 
  mutate(rev_no = row_number()) %>% 
  group_by() %>% 
  filter(!is.na(rev_name))

ggplot(revs, aes(x=rev_no, y=review_hours, col=rev_name)) + 
  geom_point(size=2) +
  geom_line(size=1) +
  xlab("Review Number") + ylab("Hours to Review") +
  theme(legend.position = "none")
```

I could do a mixed model here but clearly the answer is "not really."  If anything it goes up, but we don't have enough repreat reviewers to know. 

How well have we done with getting multiple reviewers?

```{r}
revs2 = revs %>% 
  mutate(iss_no = stri_extract_first_regex(onboarding_url, "\\d+$")) %>% 
  left_join(pkg_df, by='iss_no') %>% 
  filter(stri_detect_regex(status, "\\d")) %>% 
  filter(as.numeric(stri_extract_first_regex(status, "\\d")) > 2) %>% 
  group_by(pkgname) %>% 
  summarize(opened = opened[1], mult_reviewers = n() > 1)

ggplot(revs2, aes(x=opened, y=as.numeric(mult_reviewers))) + 
  geom_point() + 
  geom_smooth(method="glm", method.args=list(family=binomial)) +
  xlab("Date Subitted") +
  ylab("Fraction with Multiple Reviewers")
```

Much better, actually.  We've moved from it being rare to it being typical.



